{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mjvFHJFUOWx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Step 1: Upload the dataset\n",
        "print(\"Please upload 'aquatic_dataset.zip'\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Define dataset ZIP file path\n",
        "zip_path = \"aquatic_dataset.zip\"\n",
        "extract_path = \"aquatic_dataset\"\n",
        "\n",
        "# Step 2: Extract dataset\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Dataset extracted successfully!\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"Dataset ZIP file not found! Please upload 'aquatic_dataset.zip'.\")\n",
        "\n",
        "# Step 3: Define dataset paths\n",
        "dataset_path = os.path.join(extract_path, \"images\")\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "test_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "# Verify dataset structure\n",
        "if not os.path.exists(train_path) or not os.path.exists(test_path):\n",
        "    print(\"Error: Train/Test directories not found.\")\n",
        "    raise FileNotFoundError(\"Ensure that the dataset contains 'images/train' and 'images/test'.\")\n",
        "\n",
        "# Step 4: Function to load images\n",
        "def load_images(data_dir, img_size=(128, 128)):\n",
        "    categories = sorted(os.listdir(data_dir))\n",
        "    images, labels = [], []\n",
        "\n",
        "    for label, category in enumerate(categories):\n",
        "        category_path = os.path.join(data_dir, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is None:\n",
        "                print(f\"Warning: Could not read image {img_path}. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            img = cv2.resize(img, img_size) / 255.0  # Normalize\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels), categories\n",
        "\n",
        "# Load datasets\n",
        "X_train, y_train, categories = load_images(train_path)\n",
        "X_test, y_test, _ = load_images(test_path)\n",
        "\n",
        "print(f\"Loaded {len(X_train)} training images and {len(X_test)} testing images.\")\n",
        "print(f\"Categories: {categories}\")\n",
        "\n",
        "# Step 5: Load MobileNetV2 pre-trained model\n",
        "base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')#removes default classification\n",
        "base_model.trainable = False  # Freeze the base model layers\n",
        "\n",
        "# Step 6: Build the model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),#reduces overfitting\n",
        "    layers.Dense(128, activation='relu'),#it reduces vanishing gradient\n",
        "    layers.Dropout(0.2),#prevent overfitting\n",
        "    layers.Dense(len(categories), activation='softmax')#for multiclass classification,convert raw output into probabilities\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 8: Save the trained model\n",
        "model.save(\"aquatic_model_transfer_learning.keras\")\n",
        "print(\"Model saved as 'aquatic_model_transfer_learning.keras'.\")\n",
        "\n",
        "# Step 9: Function to predict an uploaded image\n",
        "def predict_image(image_path):\n",
        "    if not os.path.isfile(image_path):\n",
        "        print(\"Error: Image file not found!\")\n",
        "        return None\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(\"Error: Unable to read image. Check file format.\")\n",
        "        return None\n",
        "\n",
        "    img = cv2.resize(img, (128, 128)) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    prediction = model.predict(img)#to get class probabilities\n",
        "    category = categories[np.argmax(prediction)]\n",
        "    return category#with highest probability\n",
        "\n",
        "# Step 10: Upload an image for testing\n",
        "print(\"Upload an image to test the model:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(\"Uploaded file:\", filename)\n",
        "    display(Image(filename=filename))\n",
        "    predicted_category = predict_image(filename)\n",
        "    if predicted_category:\n",
        "        print(f\"Predicted category: {predicted_category}\")"
      ]
    }
  ]
}